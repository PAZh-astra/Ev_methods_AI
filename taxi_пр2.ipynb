{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Reinforcement Q-Learning from Scratch in Python with OpenAI Gym (обучение с подкреплением)\n",
        "https://www.learndatasci.com/tutorials/reinforcement-q-learning-scratch-python-openai-gym/"
      ],
      "metadata": {
        "id": "GN9ftpAgof7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJPqIKaM5jAC",
        "outputId": "3b7551f3-c359-472f-8cd1-9e6bc9eb0600"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import time #для управления временными задержками в коде\n",
        "from IPython.display import clear_output #управления информацией в режиме реального времени\n",
        "\n",
        "env = gym.make(\"Taxi-v3\").env #создаем среду"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-09-12T20:28:43.898684Z",
          "iopub.execute_input": "2023-09-12T20:28:43.899068Z",
          "iopub.status.idle": "2023-09-12T20:28:44.717976Z",
          "shell.execute_reply.started": "2023-09-12T20:28:43.899021Z",
          "shell.execute_reply": "2023-09-12T20:28:44.71705Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dO8YOl1of77",
        "outputId": "6bc6b694-1369-462c-9c81-4f4fe195bc1e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.s = 328\n",
        "env.reset() #сбрасывание среды к изначальному значению\n",
        "env.render() #отображает текущее состояние среды в виде текстового представления\n",
        "print(env.step(2))\n",
        "time.sleep(10) #приостанавливает выполнение программы на 10 секунд\n",
        "clear_output(wait=True)\n",
        "env.render()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-12T20:28:44.723199Z",
          "iopub.execute_input": "2023-09-12T20:28:44.72528Z",
          "iopub.status.idle": "2023-09-12T20:28:54.74358Z",
          "shell.execute_reply.started": "2023-09-12T20:28:44.725219Z",
          "shell.execute_reply": "2023-09-12T20:28:54.742821Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0h4FDc-Rof8G",
        "outputId": "0995bee0-f723-437c-fa64-22b3bb6a052c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:49: DeprecationWarning: \u001b[33mWARN: You are calling render method, but you didn't specified the argument render_mode at environment initialization. To maintain backward compatibility, the environment will render in human mode.\n",
            "If you want to render in human mode, initialize the environment in this way: gym.make('EnvName', render_mode='human') and don't call the render method.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(383, -1, False, {'prob': 1.0, 'action_mask': array([1, 1, 0, 1, 0, 0], dtype=int8)})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Решение без алгоритма RL\n",
        "Выполнение случайных действий из каждого состояния"
      ],
      "metadata": {
        "id": "-wjMDEUoof8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Устанавливаем в ноль количество итераций, штрафы и вознаграждение\n",
        "epochs = 0\n",
        "penalties, reward = 0, 0\n",
        "\n",
        "frames = [] # сохранение информации о каждом кадре среды для анимации\n",
        "\n",
        "done = False\n",
        "\n",
        "while not done:\n",
        "    action = env.action_space.sample() #выбирает случайное действие\n",
        "    state, reward, done, info = env.step(action)\n",
        "\n",
        "    if reward == -10:\n",
        "        penalties += 1\n",
        "\n",
        "    # Каждый отображенный текущий кадр помещаем в словарь/список для анимации\n",
        "    frames.append({\n",
        "        'frame': env.render(mode='ansi'),\n",
        "        'episode': '0',\n",
        "        'state': state,\n",
        "        'action': action,\n",
        "        'reward': reward\n",
        "        }\n",
        "    )\n",
        "\n",
        "    epochs += 1\n",
        "\n",
        "\n",
        "print(\"Timesteps taken: {}\".format(epochs)) #итерации\n",
        "print(\"Penalties incurred: {}\".format(penalties)) #штрафы"
      ],
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "execution": {
          "iopub.status.busy": "2023-09-12T20:28:55.084749Z",
          "iopub.execute_input": "2023-09-12T20:28:55.085029Z",
          "iopub.status.idle": "2023-09-12T20:28:55.785782Z",
          "shell.execute_reply.started": "2023-09-12T20:28:55.084989Z",
          "shell.execute_reply": "2023-09-12T20:28:55.784962Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbvRbWZSof8P",
        "outputId": "8a84897a-5cab-4344-a4c8-013923660846"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timesteps taken: 26\n",
            "Penalties incurred: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Printing frames"
      ],
      "metadata": {
        "id": "gvopsn1oof8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_frames(frames):\n",
        "    for i, frame in enumerate(frames):\n",
        "        clear_output(wait=True)\n",
        "        print(frame['frame'])\n",
        "        print(f\"Episode: {frame['episode']}\")\n",
        "        print(f\"Timestep: {i + 1}\")\n",
        "        print(f\"State: {frame['state']}\")\n",
        "        print(f\"Action: {frame['action']}\")\n",
        "        print(f\"Reward: {frame['reward']}\")\n",
        "        time.sleep(.1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-12T20:28:55.791262Z",
          "iopub.execute_input": "2023-09-12T20:28:55.793377Z",
          "iopub.status.idle": "2023-09-12T20:28:55.801154Z",
          "shell.execute_reply.started": "2023-09-12T20:28:55.793309Z",
          "shell.execute_reply": "2023-09-12T20:28:55.80034Z"
        },
        "trusted": true,
        "id": "4Xe-4GZHof8Y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_frames(frames)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-12T20:28:55.805532Z",
          "iopub.execute_input": "2023-09-12T20:28:55.807986Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5vQtWH-of8b",
        "outputId": "8cc08a44-7581-4f1e-fc2d-83b640a6e91c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35m\u001b[34;1m\u001b[43mB\u001b[0m\u001b[0m\u001b[0m: |\n",
            "+---------+\n",
            "  (Dropoff)\n",
            "\n",
            "Episode: 0\n",
            "Timestep: 26\n",
            "State: 475\n",
            "Action: 5\n",
            "Reward: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучение с подкреплением с использованием Q-Learning"
      ],
      "metadata": {
        "id": "rdRhFO6wof8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# инициализируем q- таблицу, заполняя ее нулями\n",
        "q_table = np.zeros([env.observation_space.n, env.action_space.n])"
      ],
      "metadata": {
        "trusted": true,
        "id": "fZkJ8fw1of8k"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "import random\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# устанавливаем гиперпараметры\n",
        "alpha = 0.1 #коэффициент обучения\n",
        "gamma = 0.6 #коэффициент дисконтирования\n",
        "epsilon = 0.1 #вероятность выбора случайного действия\n",
        "\n",
        "#построение метрики(показателей)\n",
        "all_epochs = []\n",
        "all_penalties = []\n",
        "\n",
        "#обучение\n",
        "for i in range(1, 100001):\n",
        "    # перезагружаем среду, чтобы начать новый эпизод\n",
        "    state = env.reset()\n",
        "\n",
        "    # инициализируем переменные для текущего эпизода\n",
        "    epochs, penalties, reward, = 0, 0, 0\n",
        "    done = False\n",
        "\n",
        "    # запускаем эпизод\n",
        "    while not done:\n",
        "        if random.uniform(0, 1) < epsilon:\n",
        "            action = env.action_space.sample() # пространство действий\n",
        "        else:\n",
        "            action = np.argmax(q_table[state])\n",
        "\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "\n",
        "        # обновляем значение q для текущей пары состояние-действие\n",
        "        old_value = q_table[state, action]\n",
        "        next_max = np.max(q_table[next_state])\n",
        "\n",
        "        # выполняем действие и наблюдаем за следующим состоянием, наградой и статусом завершения\n",
        "        new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n",
        "        q_table[state, action] = new_value\n",
        "\n",
        "        # обновить метрики, если наложен штраф\n",
        "        if reward == -10:\n",
        "            penalties += 1\n",
        "\n",
        "        state = next_state\n",
        "        epochs += 1\n",
        "\n",
        "    # печатаем номер эпизода каждые 100 эпизодов\n",
        "    if i % 100 == 0:\n",
        "        clear_output(wait=True)\n",
        "        print(f\"Episode: {i}\")\n",
        "\n",
        "print(\"Training finished.\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mujRrQXlof8l",
        "outputId": "b10f1798-1fec-444d-a313-4f20313ee09a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 100000\n",
            "Training finished.\n",
            "\n",
            "CPU times: user 1min 16s, sys: 7.83 s, total: 1min 24s\n",
            "Wall time: 1min 23s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate agent's performance after Q-learning"
      ],
      "metadata": {
        "id": "HMc-Sy-Oof8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_epochs, total_penalties = 0, 0\n",
        "episodes = 100\n",
        "frames = []\n",
        "\n",
        "for ep in range(episodes):\n",
        "    state = env.reset()\n",
        "    epochs, penalties, reward = 0, 0, 0\n",
        "\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        action = np.argmax(q_table[state]) #выбирает действие с наибольшим значением Q-таблицы для текущего состояния\n",
        "        state, reward, done, info = env.step(action)\n",
        "\n",
        "        if reward == -10:\n",
        "            penalties += 1\n",
        "\n",
        "        # Каждый отображенный кадр помещаем в словарь для анимации\n",
        "        frames.append({\n",
        "            'frame': env.render(mode='ansi'),\n",
        "            'episode': ep,\n",
        "            'state': state,\n",
        "            'action': action,\n",
        "            'reward': reward\n",
        "            }\n",
        "        )\n",
        "        epochs += 1\n",
        "\n",
        "    total_penalties += penalties\n",
        "    total_epochs += epochs\n",
        "\n",
        "print(f\"Results after {episodes} episodes:\")\n",
        "print(f\"Average timesteps per episode: {total_epochs / episodes}\")\n",
        "print(f\"Average penalties per episode: {total_penalties / episodes}\")"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sv-P2efaof8p",
        "outputId": "a74791f2-a248-41bc-8ff6-faef39630a3e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 13.02\n",
            "Average penalties per episode: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "-_SPlxZqof8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_frames(frames)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dJ2ZMUGof8r",
        "outputId": "4a0814b1-0256-4bce-ac92-a65eb42168de"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|\u001b[35m\u001b[34;1m\u001b[43mR\u001b[0m\u001b[0m\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |B: |\n",
            "+---------+\n",
            "  (Dropoff)\n",
            "\n",
            "Episode: 99\n",
            "Timestep: 1302\n",
            "State: 0\n",
            "Action: 5\n",
            "Reward: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "VH-IEYOsof8s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}